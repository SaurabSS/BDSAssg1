# Analytical Report

## We performed three tasks in this Assignment

1. Install HDFS and MapReduce
2. Run the vanilla WordCount program given in the hadoop (tutorial)[https://hadoop.apache.org/docs/stable/hadoop-mapreduce-client/hadoop-mapreduce-client-core/MapReduceTutorial.html] on three datasets.
3. Run a MapReduce based TopN program to find top 100 words across an entire corpus, for different sizes of corpus.

Installation of Hadoop is covered in `README.MD`. So we will only cover the analysis of second and third tasks in this report. 

![Sample WordCount Run on 5 Files](https://github.com/SaurabSS/BDSAssg1/blob/main/Screenshots/Screen%20Shot%202021-09-10%20at%205.59.56%20PM.png)
